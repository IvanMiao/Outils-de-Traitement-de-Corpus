# Ë©©ÂàÜÂîêÂÆãÔºö Classification po√®me-dynastie

<p style="text-align:center ;">  <a href="./doc/readme_ch.md"><u>‰∏≠Êñá</u></a>  <a href="./doc/readme_en.md"><u>English</u></a>  </p>

Ce projet s'inscrit dans le cadre du cours "Outils de Traitement de Corpus" du Master 1 Plurital.

Le dataset et le mod√®le sont tous les deux disponibles sur ü§óHugging Face : [Dataset](https://huggingface.co/datasets/IvanMiao/ch_poems_for_classification), [Model](https://huggingface.co/IvanMiao/PoemDynasty-ch-RoBERTa)

## Gestion de l'environnement

Ce projet utilise `uv` pour la gestion de l'environnement.

Pour ex√©cuter les scripts (assurez-vous d'avoir install√© `uv`):
```bash
uv run chemin/vers/le/script.py
```

## Objectif du projet

L'objectif de ce projet est d'effectuer une classification textuelle sur un corpus de po√®mes chinois classiques (√† l'exclusion des formes *ci(ËØç)* et *qu(Êõ≤)*). Le but est de pr√©dire la dynastie (par ordre chronologique : WeiJin È≠èÊôã, NanBei ÂçóÂåóÊúù, Tang Âîê, Song ÂÆã, Yuan ÂÖÉ, Ming Êòé, Qing Ê∏Ö) √† laquelle un po√®me donn√© appartient.

Bien que les formes de la po√©sie chinoise classique soient rest√©es relativement stables apr√®s la dynastie Tang, ce projet s'inspire de deux observations principales :

1.  **Linguistique** : Les caract√©ristiques linguistiques et l'usage des mots pr√©sentent des variations distinctes d'une dynastie √† l'autre.

2.  **Stylistique et th√©orie litt√©raire** : En stylistique et selon la th√©orie litt√©raire chinoise ancienne, la po√©sie de chaque dynastie poss√®de un style distinctif, souvent d√©crit comme un "zeitgeist".


## Donn√©es

Les donn√©es du projet proviennent du site *sou-yun.cn*, qui n'interdit pas l'extraction de donn√©es.

Ce site a d√©j√† classifi√© les po√®mes par dynastie et fournit un index de tous les po√®mes par auteur. Par cons√©quent, le projet utilise `request` et `bs4` pour analyser la structure HTML du site et extraire les donn√©es po√©tiques des sept dynasties s√©lectionn√©es. Pour des raisons d'efficacit√© lors de l'entra√Ænement, le script d'extraction r√©cup√®re les 20 premiers po√®mes de chaque po√®te (ou le maximum disponible si inf√©rieur √† 20) pour les dynasties comptant moins de 1000 po√®tes, et seulement les 20 premiers po√®mes des 1000 premiers po√®tes pour les dynasties plus prolifiques.

Les donn√©es obtenues sont sauvegard√©es en format `.csv`, puis fusionn√©es en un seul grand ensemble de donn√©es qui est ensuite m√©lang√© et divis√© en trois sous-ensembles : entra√Ænement/validation/test (selon un ratio **7 : 1.5 : 1.5**, avec une r√©partition r√©elle des donn√©es de **17418 : 3733 : 3738**). Ces ensembles sont stock√©s au format dataset de HuggingFace.

| Ensemble de donn√©es | Ratio           | Quantit√© r√©elle |
|---------------------|-----------------|-----------------|
| Entra√Ænement        | 7               | 17 418          |
| Validation          | 1,5             | 3 733           |
| Test                | 1,5             | 3 738           |
| **Total**           | **10**          | **24 889**      |

La visualisation des donn√©es est pr√©sent√©e ci-dessous :

![](./figures/dynasty_poems_stats.png)

Les deux premi√®res dynasties (Weijin et Nanbei) pr√©sentent le plus petit nombre de po√®mes, ce qui est logique car ce sont les dynasties les plus anciennes et donc celles dont le moins d'≈ìuvres ont √©t√© conserv√©es. La dynastie Weijin montre la longueur moyenne de po√®mes la plus √©lev√©e, car dans notre corpus, les **fu** Ëµã sont √©galement consid√©r√©s comme des po√®mes. Durant cette p√©riode, la cr√©ation de po√®mes en quatre mots et de **fu** √©tait proportionnellement plus fr√©quente que dans les six autres dynasties. Ces derni√®res, particuli√®rement apr√®s la dynastie Tang, privil√©giaient les formes po√©tiques **jueju** ÁªùÂè• (24 ou 32 caract√®res, ponctuation incluse) et **l√ºshi** ÂæãËØó (48 ou 64 caract√®res). Consid√©rant que les po√®mes de style ancien et les "fu" √©taient occasionnellement cr√©√©s et qu'ils sont beaucoup plus longs que les "jueju" et les "l√ºshi", la longueur moyenne obtenue (60-80 caract√®res) para√Æt raisonnable.

## Entra√Ænement

Ce projet utilise la [HuggingFace Text Classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) comme r√©f√©rence pour effectuer le fine-tuning des mod√®les de classification textuelle.

Le jeu de donn√©es a √©t√© entra√Æn√© sur trois mod√®les pr√©-entra√Æn√©s de type BERT :

1. `distilled-bert-multilingual`: un mod√®le BERT multilingue distill√©, permettant un entra√Ænement rapide
2. `bert-case-chinese`Ôºö un mod√®le BERT pour le chinois
3. `ethanyt/guwenbert-base`Ôºö un mod√®le bas√© sur bert-case-chinese ayant d√©j√† √©t√© fine-tun√© sur un grand corpus de textes chinois classiques

Le nombre d'√©poques (epoch) du premier mod√®le est fix√© √† 3. Afin de r√©duire le temps d'entra√Ænement, il est fix√© √† 2 pour les deux autres mod√®les plus grands. Les autres param√®tres restent inchang√©s.

En analysant les journaux de logs durant l'entra√Ænement, on a obtenu l'√©volution de la perte (Loss) par √©poque (Epoch) et les performances de chaque mod√®le sur l'ensemble de validation :

![](./figures/training_analysis.png)

On peut observer que la tendance des pertes (loss) des trois mod√®les est globalement similaire, et que `bert-case-chinese` et `ethanyt/guwenbert-base` pr√©sentent presque une √©volution parall√®le ‚Äî ce qui peut s'expliquer par le fait que le second a √©t√© fine-tun√© √† partir du premier. Un autre fait int√©ressant est que, pour `distillBERT`, la perte de validation augmente apr√®s la deuxi√®me √©poque ; cependant, par manque de temps et de ressources, il n‚Äôa pas √©t√© possible d‚Äôobserver ce ph√©nom√®ne sur les deux autres mod√®les plus grands.

## √âvaluation

Apr√®s l'entra√Ænement des trois mod√®les, une √©valuation a √©t√© effectu√© sur le sous-ensemble de test. La classe `classification_report` de `sklearn` est utilis√© pour obtenir une √©valuation plus d√©taill√©e des t√¢ches de classification.

Pour le mod√®le `distilled-bert-multilingual`, on a:

| Dynasty  | Precision | Recall  | F1-score | Support |
|----------|-----------|---------|----------|---------|
| WeiJin   | 0.5627    | 0.8248  | 0.6690   | 234     |
| NanBei   | 0.5986    | 0.5397  | 0.5676   | 315     |
| Tang     | 0.4953    | 0.3680  | 0.4222   | 568     |
| Song     | 0.3553    | 0.1211  | 0.1806   | 446     |
| Yuan     | 0.4140    | 0.5115  | 0.4576   | 823     |
| Ming     | 0.3389    | 0.3632  | 0.3506   | 782     |
| Qing     | 0.3768    | 0.4509  | 0.4105   | 570     |
| **accuracy** |           |         | 0.4248   | 3738    |
| **macro avg** | 0.4488    | 0.4542  | 0.4369   | 3738    |
| **weighted avg** | 0.4228    | 0.4248  | 0.4121   | 3738    |

<br>

Pour le mod√®le `bert-case-chinese`, on a:

| Dynasty      | Precision | Recall  | F1-score | Support |
|--------------|-----------|---------|----------|---------|
| WeiJin       | 0.6565    | 0.7350  | 0.6935   | 234     |
| NanBei       | 0.5994    | 0.6032  | 0.6013   | 315     |
| Tang         | 0.4110    | 0.5898  | 0.4845   | 568     |
| Song         | 0.3103    | 0.1413  | 0.1941   | 446     |
| Yuan         | 0.4183    | 0.5322  | 0.4684   | 823     |
| Ming         | 0.3789    | 0.4003  | 0.3893   | 782     |
| Qing         | 0.5858    | 0.2754  | 0.3747   | 570     |
| **accuracy** |           |         | 0.4462   | 3738    |
| **macro avg**| 0.4800    | 0.4682  | 0.4580   | 3738    |
| **weighted avg** | 0.4518 | 0.4462 | 0.4326   | 3738    |

<br>

Pour le mod√®le `ethanyt/guwenbert-base`, on a:

| Dynasty      | Precision | Recall  | F1-score | Support |
|--------------|-----------|---------|----------|---------|
| WeiJin       | 0.7626    | 0.8376  | 0.7984   | 234     |
| NanBei       | 0.7953    | 0.6413  | 0.7100   | 315     |
| Tang         | 0.5686    | 0.5546  | 0.5615   | 568     |
| Song         | 0.4163    | 0.2287  | 0.2952   | 446     |
| Yuan         | 0.4060    | 0.6877  | 0.5106   | 823     |
| Ming         | 0.3853    | 0.4361  | 0.4091   | 782     |
| Qing         | 0.7718    | 0.2018  | 0.3199   | 570     |
| **accuracy** |           |         | 0.4914   | 3738    |
| **macro avg**| 0.5866    | 0.5125  | 0.5150   | 3738    |
| **weighted avg** | 0.5385 | 0.4914 | 0.4771   | 3738    |

<br>

En repr√©sentant le rappel (Recall) de chaque dynastie ‚Äî c'est-√†-dire le taux de bonne pr√©diction pour les po√®mes de chaque dynastie ‚Äî sous forme de graphique, des r√©sultats obtenus sont int√©ressants :

![](./figures/evaluate_analysis.png)

Le mod√®le `ethanyt/guwenbert-base`, sp√©cialis√© en chinois classique, affiche globalement les meilleures performances avec une exactitude (accuracy) de 0.4914 et un F1-score macro moyen de 0.5150. Il est suivi par bert-case-chinese (exactitude 0.4462, F1-macro 0.4580) puis distilled-bert-multilingual (exactitude 0.4248, F1-macro 0.4369).

Les po√®mes de la dynastie **WeiJin** poss√®dent probablement des caract√©ristiques linguistiques ou stylistiques tr√®s distinctives qui les rendent plus faciles √† identifier pour les mod√®les.

La difficult√© √† classifier correctement les po√®mes de la dynastie **Song** pourrait indiquer que leurs traits stylistiques sont moins uniques, ou qu'ils partagent plus de similitudes avec les po√®mes des dynasties adjacentes (Tang, Yuan, Ming), rendant la distinction plus complexe m√™me pour un mod√®le sp√©cialis√©.

La performance plus faible du mod√®le `ethanyt/guwenbert-base` sur la po√©sie **Qing** pourrait sugg√©rer que les caract√©ristiques sur lesquelles ce mod√®le a √©t√© finement ajust√© (sp√©cifiques au chinois "classique" plus ancien) sont moins pr√©dominantes ou discriminantes pour la po√©sie Qing, ou que la po√©sie Qing pr√©sente une plus grande h√©t√©rog√©n√©it√© stylistique non captur√©e efficacement.

## Norme

Le code de ce projet a √©t√© r√©vis√© avec `pycodestyle` pour assurer sa conformit√© au PEP 8.